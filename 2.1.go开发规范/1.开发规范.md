

# 非编码类规范

## 开源规范

首先要说明的是，只有开源项目才会用到开源协议，如果你的项目不准备开源，就用不到
开源协议。但先了解一下总是没错的，以后总能用得上。
业界有上百种开源协议，每种开源协议的要求不一样，有的协议对使用条件要求比较苛
刻，有的则相对比较宽松。我们没必要全都记住，只需要知道经常使用的 6 种开源协议，
也就是 GPL、MPL、LGPL、Apache、BSD 和 MIT 就可以了。


那具体如何选择适合自己的开源协议呢？你可以参考乌克兰程序员 Paul Bagwell 画的这张图：
![alt text](image.png)


1. 第一，开源项目，应该有一个高的单元覆盖率。这样，一方面可以确保第三方开发者在开发完代码之后，能够很方便地对整个项目做详细的单元测试，另一方面也能保证提交代码的质量。
   
1. 第二，要确保整个代码库和提交记录中，不能出现内部 IP、内部域名、密码、密钥这类信息。否则，就会造成敏感信息外漏，可能会对我们的内部业务造成安全隐患。

1. 第三，当我们的开源项目被别的开发者提交 pull request、issue、评论时，要及时处理，一方面可以确保项目不断被更新，另一方面也可以激发其他开发者贡献代码的积极性。
   
2. 第四，好的开源项目，应该能够持续地更新功能，修复 Bug。对于一些已经结项、不维护的开源项目，需要及时地对项目进行归档，并在项目描述中加以说明。

## 文档规范

### README 规范
README 文档是项目的门面，它是开发者学习项目时第一个阅读的文档，会放在项目的根
目录下。因为它主要是用来介绍项目的功能、安装、部署和使用的，所以它是可以规范化
的。
下面，我们直接通过一个 README 模板，来看一下 README 规范中的内容：
```html
# 项目名称
<!-- 写一段简短的话描述项目 -->

## 功能特性
<!-- 描述该项目的核心功能点 -->

## 软件架构(可选)
<!-- 可以描述下项目的架构 -->


## 快速开始

### 依赖检查
<!-- 描述该项目的依赖，比如依赖的包、工具或者其他任何依赖项 -->

### 构建
<!-- 描述如何构建该项目 -->

### 运行
<!-- 描述如何运行该项目 -->

## 使用指南
<!-- 描述如何使用该项目 -->

## 如何贡献
<!-- 告诉其他开发者如果给该项目贡献源码 -->

## 社区(可选)
<!-- 如果有需要可以介绍一些社区相关的内容 -->

## 关于作者
<!-- 这里写上项目作者 -->

## 谁在用(可选)
<!-- 可以列出使用本项目的其他有影响力的项目，算是给项目打个广告吧 -->

## 许可证
<!-- 这里链接上该项目的开源许可证 -->
```
### 项目文档规范

项目文档包括一切需要文档化的内容，它们通常集中放在 /docs 目录下。当我们在创建团队的项目文档时，通常会预先规划并创建好一些目录，用来存放不同的文档。因此，在开始 Go 项目开发之前，我们也要制定一个软件文档规范。好的文档规范有 2 个优点：易读和可以快速定位文档。

不同项目有不同的文档需求，在制定文档规范时，你可以考虑包含两类文档。为了方便全球开发者和用户使用，开发文档和用户文档，可以预先规划好英文和中文 2 个版本。为了加深你的理解，这里我们来看下实战项目的文档目录结构：


- 开发文档：用来说明该项目的开发流程，比如如何搭建开发环境、构建二进制文件、测试、部署等。

- 用户文档：软件的使用文档，对象一般是软件的使用者，内容可根据需要添加。比如，可以包括 API 文档、SDK 文档、安装文档、功能介绍文档、最佳实践、操作指南、常见问题等。

```
docs
│── devel
│ ├── en-US/                # 英文版文档，可以根据需要组织文件结构
│ └── zh-CN                 # 中文版文档，可以根据需要组织文件结构
│ └── development.md        # 开发手册，可以说明如何编译、构建、运行项目
├── guide                   # 用户文档
│ ├── en-US/                # 英文版文档，可以根据需要组织文件结构
│ └── zh-CN                 # 中文版文档，可以根据需要组织文件结构
│ ├── api/                  # API文档
│ ├── best-practice         # 最佳实践，存放一些比较重要的实践文章
│ │ └── authorization.md
│ ├── faq                   # 常见问题
│ │ ├── iam-apiserver
│ │ └── installation
│ ├── installation          # 安装文档
│ │ └── installation.md
│ ├── introduction/         # 产品介绍文档
│ ├── operation-guide       # 操作指南，里面可以根据RESTful资源再划分为更细的
│ │ ├── policy.md
│ │ ├── secret.md
│ │ └── user.md
│ ├── quickstart            # 快速入门
│ │ └── quickstart.md
│ ├── README.md             # 用户文档入口文件
│ └── sdk                   # SDK文档
│ └── golang.md
└── images                  # 图片存放目录
└── 部署架构v1.png
```

### API 接口文档规范
![alt text](image-1.png)

一个规范的 API 接口文档，通常需要包含:
1. 一个完整的 API 接口介绍文档 - API 接口使用文档中需要包含接口描述、请求方法、请求参数、输出参数和请求示例。
2. API 接口变更历史文档
3. 通用说明
4. 数据结构说明
5. 错误码描述和 API 接口使用文档。




以Markdown 为例接口文档拆分为以下几个 Markdown 文件，并存放在目录 docs/guide/zh-CN/api中：


- `README.md` ：API 接口介绍文档，会分类介绍 IAM 支持的 API 接口，并会存放相关 API 接口文档的链接，方便开发者查看。

- `CHANGELOG.md` ：API 接口文档变更历史，方便进行历史回溯，也可以使调用者决定是否进行功能更新和版本更新。

- `generic.md` ：用来说明通用的请求参数、返回参数、认证方法和请求方法等。
  
- `struct.md` ：用来列出接口文档中使用的数据结构。这些数据结构可能被多个 API 接口使用，会在 `user.md`、`secret.md`、`policy.md` 文件中被引用。

- `user.md` 、 `secret.md` 、 `policy.md` ：API 接口文档，相同 REST 资源的接口会存放在一个文件中，以 REST 资源名命名文档名。

- `error_code.md` ：错误码描述，通过程序自动生成。

这里我拿 user.md 接口文档为例，和你解释下接口文档是如何写的。user.md 文件记录
了用户相关的接口，每个接口按顺序排列，包含如下 5 部分。

- **接口描述**：描述接口实现了什么功能。
- **请求方法**：接口的请求方法，格式为 HTTP 方法 请求路径，例如 POST /v1/users。在 通用说明中的请求方法部分，会说明接口的请求协议和请求地址。
  
- **输入参数**：接口的输入字段，它又分为 Header 参数、Query 参数、Body 参数、Path参数。每个字段通过：`参数名称`、`必选`、`类型` 和 `描述` 4 个属性来描述。如果参数有限制或者默认值，可以在描述部分注明。
  
- **输出参数**：接口的返回字段，每个字段通过 `参数名称`、`类型` 和 `描述` 3 个属性来描述。
  
- **请求示例**：一个真实的 API 接口请求和返回示例




## 版本规范

在做 Go 项目开发时，我建议你把所有组件都加入版本机制。原因主要有两个：
- 一是通过版本号，我们可以很明确地知道组件是哪个版本，从而定位到该组件的功能和代码，方便我们定位问题。
- 二是发布组件时携带版本号，可以让使用者知道目前的项目进度，以及使用版本和上一个版本的功能差别等。


目前业界主流的版本规范是语义化版本规范，也是 IAM 系统采用的版本规范。

### 那什么是语义化版本规范呢？


语义化版本规范（SemVer，Semantic Versioning）是 GitHub 起草的一个具有指导意义的、统一的版本号表示规范。它规定了版本号的表示、增加和比较方式，以及不同版本号代表的含义。

在这套规范下，版本号及其更新方式包含了相邻版本间的底层代码和修改内容的信息。语义化版本格式为：*主版本号.次版本号.修订号（X.Y.Z）*，其中 X、Y 和 Z 为非负的整数，且禁止在数字前方补零。

版本号可按以下规则递增：

- 主版本号（MAJOR）：当做了不兼容的 API 修改。
  
- 次版本号（MINOR）：当做了向下兼容的功能性新增及修改。这里有个不成文的约定需要你注意，偶数为稳定版本，奇数为开发版本。
  
- 修订号（PATCH）：当做了向下兼容的问题修正。

例如，v1.2.3 是一个语义化版本号，版本号中每个数字的具体含义见下图：
![alt text](image-2.png)


你可能还看过这么一种版本号：*v1.2.3-alpha*。这其实是把先行版本号（Pre-release）和版本编译元数据，作为延伸加到了主版本号.次版本号.修订号的后面，格式为 X.Y.Z[-先行版本号][+版本编译元数据]，如下图所示：


![alt text](image-3.png)


先行版本号意味着，该版本不稳定，可能存在兼容性问题，格式为：X.Y.Z-[一连串以句点分隔的标识符] ，比如下面这几个例子：
```
1.0.0-alpha
1.0.0-alpha.1
1.0.0-0.3.7
1.0.0-x.7.z.92
```
编译版本号，一般是编译器在编译过程中自动生成的，我们只定义其格式，并不进行人为控制。下面是一些编译版本号的示例：
```
1.0.0-alpha+001
1.0.0+20130313144700
1.0.0-beta+exp.sha.5114f85
```

### 如何确定版本号？
- 第一，在实际开发的时候，我建议你使用 0.1.0 作为第一个开发版本号，并在后续的每次发行时递增次版本号。
  
- 第二，当我们的版本是一个稳定的版本，并且第一次对外发布时，版本号可以定为 1.0.0。
- 
- 第三，当我们严格按照 Angular commit message 规范提交代码时，版本号可以这么来确定：
    - fix 类型的 commit 可以将修订号 +1。
    - feat 类型的 commit 可以将次版本号 +1。
    - 带有 BREAKING CHANGE 的 commit 可以将主版本号 +1。



## Commit规范


使用git查找日志:
基于这些 Commit Message 进行过滤查找，比如只查找某个版本新增的功能：
```bash
git log --oneline --grep "^feat|^fix|^perf"。
```


```

<type>([optional scope]): <description>
// 空行
[optional body]
// 空行
[optional footer(s)]
```
示例

![alt text](image-4.png)


Header 部分只有一行，包括三个字段：type（必选）、scope（可选）和 subject（必选）。


**type**

![alt text](image-5.png)
有这么多 type，我们该如何确定一个 commit 所属的 type 呢？这里我们可以通过下面这张图来确定

![alt text](image-6.png)

**scope**

scope 是用来说明 commit 的影响范围的，它必须是名词。显然，不同项目会有不同的scope。在项目初期，我们可以设置一些粒度比较大的 scope，比如可以按组件名或者功能来设置 scope；后续，如果项目有变动或者有新功能，我们可以再用追加的方式添加新的 scope。

**subject**


subject 是 commit 的简短描述，必须以动词开头、使用现在时。比如，我们可以用change，却不能用 changed 或 changes，而且这个动词的第一个字母必须是小写。通过这个动词，我们可以明确地知道 commit 所执行的操作。此外我们还要注意，subject 的结尾不能加英文句号。

**Body**

Body 部分可以分成多行，而且格式也比较自由。不过，和 Header 里的一样，它也要以动词开头，使用现在时。此外，它还必须要包括修改的动机，以及和跟上一版本相比的改动点。

**Footer**



### 提交频率

一种情况是，只要我对项目进行了修改，一通过测试就立即 commit。比如修复完一个 bug、开发完一个小功能，或者开发完一个完整的功能，测试通过后就提交。

另一种情况是，我们规定一个时间，定期提交。这里我建议代码下班前固定提交一次，并且要确保本地未提交的代码，延期不超过 1 天。这样，如果本地代码丢失，可以尽可能减少丢失的代码量。


按照上面 2 种方式提交代码，你可能会觉得代码 commit 比较多，看起来比较随意。或者说，我们想等开发完一个完整的功能之后，放在一个 commit 中一起提交。这时候，我们可以在最后合并代码或者提交 Pull Request 前，执行 git rebase -i 合并之前的所有commit。


那么如何合并 commit 呢？接下来，我来详细说说。


### 合并提交

合并提交，就是将多个 commit 合并为一个 commit 提交。这里，我建议你把新的commit 合并到主干时，只保留 2~3 个 commit 记录。那具体怎么做呢？


在 Git 中，我们主要使用 git rebase 命令来合并。git rebase 也是我们日后开发需要经常使用的一个命令，所以我们一定要掌握好它的使用方法

**git rebase 命令介绍**


> git rebase 的最大作用是它可以重写历史。

我们通常会通过 git rebase -i <commit ID>使用 git rebase 命令，-i 参数表示交互（interactive），该命令会进入到一个交互界面中，其实就是 Vim 编辑器。在该界面中，我们可以对里面的 commit 做一些操作，交互界面如图所示：

![alt text](image-7.png)

### 合并提交操作示例

使用小乌龟




## 工作流

### 集中式工作流


我们先来看看集中式工作流，它是最简单的一种开发方式。集中式工作流的工作模式如下图所示：


![alt text](image-9.png)

所有人在同一 分支上协作
![alt text](image-10.png)

适合用在团队人数少、开发不频繁、不需要同时维护多个版本的小项目中


### 功能分支工作流

功能分支工作流基于集中式工作流演进而来。在开发新功能时，基于 master 分支新建一个功能分支，在功能分支上进行开发，而不是直接在本地的 master 分支开发，开发完成之后合并到 master 分支，如下图所示：

![alt text](image-11.png)


相较于集中式工作流，这种工作流让不同功能在不同的分支进行开发，只在最后一步合并到 master 分支，不仅可以避免不同功能之间的相互影响，还可以使提交历史看起来更加简洁。

还有，在合并到 master 分支时，需要提交 PR（pull request），而不是直接将代码merge 到 master 分支。PR 流程不仅可以把分支代码提供给团队其他开发人员进行CR（Code Review），还可以在 PR 页面讨论代码。通过 CR ，我们可以确保合并到master 的代码是健壮的；通过 PR 页面的讨论，可以使开发者充分参与到代码的讨论中，

有助于提高代码的质量，并且提供了一个代码变更的历史回顾途径。


那么，功能分支工作流具体的开发流程是什么呢？我们一起来看下。

1. 基于 master 分支新建一个功能分支，功能分支可以取一些有意义的名字，便于理解，

    例如 feature/rate-limiting。
    ```bash
    $ git checkout -b feature/rate-limiting
    ```
1. 在功能分支上进行代码开发，开发完成后 commit 到功能分支。
   
    ```bash
    $ git add limit.go
    $ git commit -m "add rate limiting"
    ```
1. 将本地功能分支代码 push 到远程仓库。
   ```bash
   $ git push origin feature/rate-limiting
   ```
1. 在远程仓库上创建 PR（例如：GitHub）。
   
   ![alt text](image-12.png)

    点击 Compare & pull request 后会进入 PR 页面，在该页面中可以根据需要填写评论，最后点击 Create pull request 提交 PR。


1. 代码管理员收到 PR 后，可以 CR 代码，CR 通过后，再点击 Merge pull request 将PR 合并到 master，如下图所示。

### Git Flow 工作流 - todo


Git Flow 工作流是一个非常成熟的方案，也是非开源项目中最常用到的工作流。它定义了一个围绕项目发布的严格分支模型，通过为代码开发、发布和维护分配独立的分支来让项目的迭代流程更加顺畅，比较适合大型的项目或者迭代速度快的项目。接下来，我会通过介绍 Git Flow 的 5 种分支和工作流程，来给你讲解 GIt Flow 是如何工作的。

![alt text](image-14.png)

#### Git Flow 的 5 种分支

Git Flow 中定义了 5 种分支，分别是 `master`、`feature` 、`release` 和 `hotfix`。其中， `master`  和 `develop` 为常驻分支，其他为非常驻分支，不同的研发阶段会用到不同的分支。这 5 种分支的详细介绍见下表：

![alt text](image-13.png)





## 发布规范



# 开发规范

1. 目录结构
2. 模块拆分

## 目录规范

**规范要求**

- 命名清晰：目录命名要清晰、简洁，不要太长，也不要太短，目录名要能清晰地表达出该目录实现的功能，并且目录名最好用单数。一方面是因为单数足以说明这个目录的功能，另一方面可以统一规范，避免单复混用的情况。
  
- 功能明确：一个目录所要实现的功能应该是明确的、并且在整个项目目录中具有很高的辨识度。也就是说，当需要新增一个功能时，我们能够非常清楚地知道把这个功能放在哪个目录下。
  
- 全面性：目录结构应该尽可能全面地包含研发过程中需要的功能，例如文档、脚本、源码管理、API 实现、工具、第三方包、测试、编译产物等。
  
- 可预测性：项目规模一定是从小到大的，所以一个好的目录结构应该能够在项目变大时，仍然保持之前的目录结构。
  
- 可扩展性：每个目录下存放了同类的功能，在项目变大时，这些目录应该可以存放更多同类功能。

### 平铺式目录结构


一个 Go 项目可以是一个应用，也可以是一个代码框架 / 库，当项目是代码框架 / 库时，比较适合采用平铺式目录结构。




平铺方式就是在项目的根目录下存放项目的代码，整个目录结构看起来更像是一层的，这种方式在很多框架 / 库中存在，使用这种方式的好处是引用路径长度明显减少，

比如： 
github.com/marmotedu/log/pkg/options，
可缩短为
github.com/marmotedu/log/options。


例如 log 包 github.com/golang/glog 就是平铺式的，目录如下：

```bash
$ ls glog/
glog_file.go glog.go glog_test.go LICENSE README
```


接下来，我们来学习结构化目录结构，它比较适合 Go 应用，也比较复杂。

### 结构化目录结构

一个 Go 项目包含 3 大部分：`Go 应用` 、`项目管理` 、 `文档` 。所以，我们的项目目录也可以分为这 3 大类。同时，Go 应用又贯穿开发阶段、测试阶段和部署阶段，相应的应用类的目录，又可以按开发流程分为更小的子类。当然了，这些是我建议的目录，Go项目目录中还有一些不建议的目录。所以整体来看，我们的目录结构可以按下图所示的方式来分类：



![alt text](image-8.png)

## 模块拆分


### 按层拆分

最典型的是 MVC 架构中的模块拆分方式。在 MVC 架构中，我们将服务中的不同组件按访问顺序，拆分成了 Model、View 和 Controller 三层。


### 按功能拆分

在 Go 项目中我建议你使用的是按功能拆分的方法，这也是 Go 项目中最常见的拆分方法。

比如，一个订单系统，我们可以根据不同功能将其拆分成用户（user）、订单（order）和计费（billing）3 个模块，每一个模块提供独立的功能，功能更单一



## 代码规范



go 静态代码检查工具： golangci-lint
## 代码质量

### 单元测试


如果我们要对函数 A 进行测试，并且 A 中的所有代码均能够在单元测试环境下按预期被执行，那么函数 A 的代码块就是可测试的。我们来看下一般的单元测试环境有什么特点：


- 可能无法连接数据库。
- 可能无法访问第三方服务。

如果函数 A 依赖数据库连接、第三方服务，那么在单元测试环境下执行单元测试就会失败，函数就没法测试，函数是不可测的。

解决方法也很简单：将依赖的数据库、第三方服务等抽象成接口，在被测代码中调用接口的方法，在测试时传入 mock 类型，从而将数据库、第三方服务等依赖从具体的被测函数中解耦出去：

```go
package post

import "google.golang.org/grpc"

type Post struct {
    Name string
    Address string
}
func ListPosts(client *grpc.ClientConn) ([]*Post, error) {
    return client.ListPosts()
}
```

这段代码中的 ListPosts 函数是不可测试的。因为 ListPosts 函数中调用了client.ListPosts()方法，该方法依赖于一个 gRPC 连接。而我们在做单元测试时，可能因为没有配置 gRPC 服务的地址、网络隔离等原因，导致没法建立 gRPC 连接，从而导致 ListPosts 函数执行失败。

下面，我们把这段代码改成可测试的，如下：

```go

package main
type Post struct {
    Name string
    Address string
}
type Service interface {
    ListPosts() ([]*Post, error)
}

func ListPosts(svc Service) ([]*Post, error) {
    return svc.ListPosts()
}
```
上面代码中，ListPosts 函数入参为 Service 接口类型，只要我们传入一个实现了 Service接口类型的实例，ListPosts 函数即可成功运行。因此，我们可以在单元测试中可以实现一个不依赖任何第三方服务的 fake 实例，并传给 ListPosts。上述可测代码的单元测试代码

如下：
```go
package main
import "testing"
type fakeService struct {
}

func NewFakeService() Service {
    return &fakeService{}
}
func (s *fakeService) ListPosts() ([]*Post, error) {
    posts := make([]*Post, 0)
    posts = append(posts, &Post{
        Name: "colin",
        Address: "Shenzhen",
    })
    posts = append(posts, &Post{
        Name: "alex",
        Address: "Beijing",
    })
    return posts, nil
}

func TestListPosts(t *testing.T) {
    fake := NewFakeService()
    if _, err := ListPosts(fake); err != nil {
        t.Fatal("list posts failed")
    }
}
```

当我们的代码可测之后，就可以借助一些工具来 Mock 需要的接口了。常用的 Mock 工具，有这么几个：


- golang/mock，是官方提供的 Mock 框架。它实现了基于 interface 的 Mock 功能，能够与 Golang 内置的 testing 包做很好的集成，是最常用的 Mock 工具。golang/mock 提供了 mockgen 工具用来生成 interface 对应的 Mock 源文件。

- sqlmock，可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。



- httpmock，可以用来 Mock HTTP 请求。


- bouk/monkey，猴子补丁，能够通过替换函数指针的方式来修改任意函数的实现。如果 golang/mock、sqlmock 和 httpmock 这几种方法都不能满足我们的需求，我们可以尝试通过猴子补丁的方式来 Mock 依赖。可以这么说，猴子补丁提供了单元测试Mock 依赖的最终解决方案。

接下来，我们再一起看看如何提高我们的单元测试覆盖率。

- 使用 gotests 工具自动生成单元测试代码，减少编写单元测试用例的工作量，将你从重复的劳动中解放出来。

- 定期检查单元测试覆盖率。你可以通过以下方法来检查：
```bash
# 运行当前目录下的所有测试，并启用竞态条件检测、测试覆盖率分析，并将覆盖率数据输出到coverage.out文件，同时设置测试的超时时间和以详细模式运行。
go test -race -cover -coverprofile=./coverage.out -timeout=10m -short -v ./

# 读取和分析coverage.out文件中的覆盖率数据，并以函数为单位显示每个函数的代码覆盖率。
go tool cover -func ./coverage.out
```
### 编程哲学


#### 面相接口编程

```go
package mainimport"fmt"

// 定义了一个鸟类
type Bird interface {  
    Fly()  
    Type() string
}

// 鸟类：金丝雀
type Canary struct { 
     Name string
}

func(c *Canary)Fly() {  
    fmt.Printf("我是%s，用黄色的翅膀飞\n", c.Name)
}

func(c *Canary)Type()string {
    return c.Name
}
// 鸟类：乌鸦
type Crow struct {
    Name string
}
func(c *Crow)Fly() {  
    fmt.Printf("我是%s，我用黑色的翅膀飞\n", c.Name)
}
func(c *Crow)Type()string {
    return c.Name
}

// 让鸟类飞一下
funcLetItFly(bird Bird) {  
    fmt.Printf("Let %s Fly!\n", bird.Type()) 
    bird.Fly()
}

func main() {  
    LetItFly(&Canary{"金丝雀"})  
    LetItFly(&Crow{"乌鸦"})
}
```
#### 面向对象编程
```go
package main

import (
	"fmt"
	"strconv"
	"testing"
)

type Bird struct{ Type string }

// 鸟的类别
func (bird *Bird) Class() string { return bird.Type } // 定义了一个鸟类
type Birds interface {
	Name() string
	Class() string
}
type Canary struct {
	Bird
	name string
}

func (c *Canary) Name() string { return c.name }

// 鸟类：乌鸦
type Crow struct {
	Bird
	name string
}

func (c *Crow) Name() string { return c.name }
func NewCrow(name string) *Crow {
	return &Crow{Bird: Bird{Type: "Crow"}, name: name}
}
func NewCanary(name string) *Canary {
	return &Canary{Bird: Bird{Type: "Canary"}, name: name}
}
func BirdInfo(birds Birds) {
	fmt.Printf("I'm %s, I belong to %s bird class!\n", birds.Name(), birds.Class())
}

func Test199(t *testing.T) {

	var birds []Birds
	for i := 0; i < 10; i++ {

        // interface{} = Object
		a := (interface{})(NewCanary("-" + strconv.Itoa(i)))
		fmt.Println(a)
		if i%2 == 0 {
            //使用强转方式
            //父类 = 子类
			var b = Birds(NewCanary("A" + strconv.Itoa(i)))
			birds = append(birds, b)
		} else {
			var b = Birds(NewCrow("B" + strconv.Itoa(i)))
			birds = append(birds, b)
		}
	}

    //打印
	for i := 0; i < len(birds); i++ {
		var b = birds[i]
		BirdInfo(b)
	}
}
```
### 软件设计方法

优秀的软件设计方法有很多，其中有两类方法对我们代码质量的提升特别有帮助，分别是设计模式（Design pattern）和 SOLID 原则


#### SOLID原则


- 单一职责原则（Single Responsibility Principle, SRP）：一个类应该只有一个引起变化的原因。这意味着一个类应该只负责一件事情，如果类承担了多个职责，那么当这些职责发生变化时，这个类就可能变得难以理解和维护。
  
- 开闭原则（Open-Closed Principle, OCP）：软件实体（如类、模块或函数）应该对扩展开放，对修改封闭。这意味着新的功能应该通过添加代码来实现，而不是修改现有的代码。
  
- 里氏替换原则（Liskov Substitution Principle, LSP）：子类必须能够替换它们的基类，且程序的行为不会发生改变。这确保了继承的复用性和正确性。
  
- 接口隔离原则（Interface Segregation Principle, ISP）：客户端不应该被迫依赖于它们不需要的方法或属性。接口应该尽可能地小且具体，以满足特定客户端的需求。

- 依赖倒置原则（Dependency Inversion Principle, DIP）：高层模块不应该依赖于低层模块，它们都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。这有助于减少代码之间的耦合度，提高系统的可维护性和可扩展性。

## 自动生成代码

错误码、错误码说明文档。
自动生成缺失的 doc.go 文件。
利用 gotests 工具，自动生成单元测试用例。
使用 Swagger 工具，自动生成 Swagger 文档。
使用 Mock 工具，自动生成接口的 Mock 实例。


## 利用工具

利用工具的确定性，可以确保执行结果的一致性。例如，使用 golangci-lint 对代码进行检查，可以确保不同开发者开发的代码至少都遵循 golangci-lint 的代码检查规范。

有利于实现自动化，可以将工具集成到 CI/CD 流程中，触发流水线自动执行。

## 对接 CI/CD


代码在合并入主干时，应该有一套 CI/CD 流程来自动化地对代码进行检查、编译、单元测试等，只有通过后的代码才可以并入主干。通过 CI/CD 流程来保证代码的质量。当前比较流行的 CI/CD 工具有 Jenkins、GitLab、Argo、Github Actions、JenkinsX 等。

## 接口规范



## 日志规范
## 错误码规范

# RESTful设计

![alt text](image-16.png)


REST 风格虽然适用于很多传输协议，但在实际开发中，由于 REST 天生和 HTTP 协议相辅相成，因此 HTTP 协议已经成了实现 RESTful API 事实上的标准。所以，REST 具有以下核心特点：


以资源 (resource) 为中心，所有的东西都抽象成资源，所有的行为都应该是在资源上的
CRUD 操作。

- 资源对应着面向对象范式里的对象，面向对象范式以对象为中心。
  
- 资源使用 URI 标识，每个资源实例都有一个唯一的 URI 标识。
  
  例如，如果我们有一个用户，用户名是 admin，那么它的 URI 标识就可以是 /users/admin。

  ## URI 设计

资源都是使用 URI 标识的，我们应该按照一定的规范来设计 URI，通过规范化可以使我们的 API 接口更加易读、易用。以下是 URI 设计时，应该遵循的一些规范：


资源名使用名词而不是动词，并且用名词复数表示。资源分为 Collection 和 Member两种。

- Collection：一堆资源的集合。例如我们系统里有很多用户（User）, 这些用户的集合就是 Collection。Collection 的 URI 标识应该是 域名/资源名复数, 
  例如: https:// iam.api.marmotedu.com/users。

- Member：单个特定资源。例如系统中特定名字的用户，就是 Collection 里的一个Member。Member 的 URI 标识应该是 域名/资源名复数/资源名称, 
  例如:https:// iam.api.marmotedu/users/admin。



其他规范

- URI 结尾不应包含/
  
- URI 中不能出现下划线 _，必须用中杠线 -代替（有些人推荐用 _，有些人推荐用 -，统一使用一种格式即可，我比较推荐用 -）。
  
- URI 路径用小写，不要用大写

- 避免层级过深的 URI。超过 2 层的资源嵌套会很乱，建议将其他资源转化为?参数，比如：
    ```go
    /schools/tsinghua/classes/rooma/students/zhang # 不推荐
    /students?school=qinghua&class=rooma # 推荐
    ```
    这里有个地方需要注意：在实际的 API 开发中，可能你会发现有些操作不能很好地映射为一个 REST 资源，这时候，你可以参考下面的做法。
    
    将一个操作变成资源的一个属性，比如想在系统中暂时禁用某个用户，可以这么设计URI：/users/zhangsan?active=false。
    将操作当作是一个资源的嵌套资源，比如一个 GitHub 的加星操作：
    ```go
    PUT /gists/:id/star # github star action
    DELETE /gists/:id/star # github unstar action
    ```

**REST 资源操作映射为 HTTP 方法**

基本上 RESTful API 都是使用 HTTP 协议原生的 GET、PUT、POST、DELETE 来标识对资源的 CRUD 操作的，形成的规范如下表所示：
![alt text](image-17.png)

对资源的操作应该满足安全性和幂等性：
- 安全性：不会改变资源状态，可以理解为只读的。
- 幂等性：执行 1 次和执行 N 次，对资源状态改变的效果是等价的。

使用不同 HTTP 方法时，资源操作的安全性和幂等性对照见下表：  
![alt text](image-18.png)

在使用 HTTP 方法的时候，有以下两点需要你注意：

GET 返回的结果，要尽量可用于 PUT、POST 操作中。例如，用 GET 方法获得了一个user 的信息，调用者修改 user 的邮件，然后将此结果再用 PUT 方法更新。这要求GET、PUT、POST 操作的资源属性是一致的。

如果对资源进行状态 / 属性变更，要用 PUT 方法，POST 方法仅用来创建或者批量删除这两种场景


在设计 API 时，经常会有批量删除的需求，需要在请求中携带多个需要删除的资源名，但是 HTTP 的 DELETE 方法不能携带多个资源名，这时候可以通过下面三种方式来解决：

- 发起多个 DELETE 请求。
- 操作路径中带多个 id，id 之间用分隔符分隔, 例如：DELETE /users?ids=1,2,3 。
- 直接使用 POST 方式来批量删除，body 中传入需要删除的资源列表
  
其中，第二种是我最推荐的方式，因为使用了匹配的 DELETE 动词，并且不需要发送多次DELETE 请求。

## 统一的返回格式


一般来说，一个系统的 RESTful API 会向外界开放多个资源的接口，每个接口的返回格式要保持一致。另外，每个接口都会返回成功和失败两种消息，这两种消息的格式也要保持一致。不然，客户端代码要适配不同接口的返回格式，每个返回格式又要适配成功和失败两种消息格式，会大大增加用户的学习和使用成本。

## API 版本管理


但在实际场景中，很可能会出现同一个 API 无法向下兼容的情况。这时候最好的解决办法是从一开始就引入 API 版本机制，当不能向下兼容时，就引入一个新的版本，老的版本则保留原样。这样既能保证服务的可用性和安全性，同时也能满足新需求。API 版本有不同的标识方法，在 RESTful API 开发中，通常将版本标识放在如下 3 个位置：

- URL 中，比如/v1/users。
- HTTP Header 中，比如Accept: vnd.example-com.foo+json; version=1.0。
- Form 参数中，比如/users?version=v1。

放在 URL 中的，比如/v1/users，这样做的好处是很直观，GitHub、Kubernetes、Etcd 等很多优秀的 API 均采用这种方式。



## API 命名
API 通常的命名方式有三种，分别是驼峰命名法 (serverAddress)、蛇形命名法(server_address) 和脊柱命名法 (server-address)。

## 统一分页 / 过滤 / 排序 / 搜索功能


- 分页：在列出一个 Collection 下所有的 Member 时，应该提供分页功能，例如/users?offset=0&limit=20（limit，指定返回记录的数量；offset，指定返回记录的开始位置）。引入分页功能可以减少 API 响应的延时，同时可以避免返回太多条目，导致服务器 / 客户端响应特别慢，甚至导致服务器 / 客户端 crash 的情况。

- 过滤：如果用户不需要一个资源的全部状态属性，可以在 URI 参数里指定返回哪些属性，例如/users?fields=email,username,address。

- 排序：用户很多时候会根据创建时间或者其他因素，列出一个 Collection 中前 100 个Member，这时可以在 URI 参数中指明排序参数，例如/users?sort=age,desc。

- 搜索：当一个资源的 Member 太多时，用户可能想通过搜索，快速找到所需要的Member，或着想搜下有没有名字为 xxx 的某类资源，这时候就需要提供搜索功能。搜索建议按模糊匹配来搜索。

## 域名

API 的域名设置主要有两种方式：



- https://marmotedu.com/api ，这种方式适合 API 将来不会有进一步扩展的情况，比如刚开始 marmotedu.com 域名下只有一套 API 系统，未来也只有这一套 API 系统。
  
- https://iam.api.marmotedu.com，如果 marmotedu.com 域名下未来会新增另一个系统 API，这时候最好的方式是每个系统的 API 拥有专有的 API 域名，比如：storage.api.marmotedu.com，network.api.marmotedu.com。腾讯云的域名就是采用这种方式。

# RPC API

根据维基百科的定义，RPC（Remote Procedure Call），即远程过程调用，是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员不用额外地为这个交互作用编程。

RPC 的调用过程如下图所示：
![alt text](image-19.png)


RPC 调用具体流程如下：

1. Client 通过本地调用，调用 Client Stub。
   
2. Client Stub 将参数打包（也叫 Marshalling）成一个消息，然后发送这个消息。
   
3. Client 所在的 OS 将消息发送给 Server。
   
4. Server 端接收到消息后，将消息传递给 Server Stub。
   
5. Server Stub 将消息解包（也叫 Unmarshalling）得到参数。Server Stub 调用服务端的子程序（函数），处理完后，将最终结果按照相反的步骤返回给 Client。



这里需要注意，Stub 负责调用参数和返回值的流化（serialization）、参数的打包和解包，以及网络层的通信。Client 端一般叫 Stub，Server 端一般叫 Skeleton。

目前，业界有很多优秀的 RPC 协议，例如腾讯的 Tars、阿里的 Dubbo、微博的Motan、Facebook 的 Thrift、RPCX，等等。但使用最多的还是gRPC，这也是本专栏所采用的 RPC 框架，所以接下来我会重点介绍 gRPC 框架。


## gRPC 介绍

gRPC 是由 Google 开发的高性能、开源、跨多种编程语言的通用 RPC 框架，基于 HTTP2.0 协议开发，默认采用 Protocol Buffers 数据序列化协议。gRPC 具有如下特性：

支持多种语言，例如 Go、Java、C、C++、C#、Node.js、PHP、Python、Ruby 等。

基于 IDL（Interface Definition Language）文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub。通过这种方式，也可以将服务端和客户端解耦，使客户端和服务端可以并行开发。通信协议基于标准的 HTTP/2 设计，支持双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性。

支持 Protobuf 和 JSON 序列化数据格式。Protobuf 是一种语言无关的高性能序列化框架，可以减少网络传输流量，提高通信效率。

![alt text](image-20.png)



像很多其他的 RPC 服务一样，gRPC 也是通过 IDL 语言，预先定义好接口（接口的名字、传入参数和返回参数等）。在服务端，gRPC 服务实现我们所定义的接口。在客户端，gRPC 存根提供了跟服务端相同的方法。

gRPC API 接口通常使用的数据传输格式是 Protocol Buffers。

## Protocol Buffers 介绍


Protocol Buffers（ProtocolBuffer/ protobuf）是 Google 开发的一套对数据结构进行序列化的方法，可用作（数据）通信协议、数据存储格式等，也是一种更加灵活、高效的数据格式，与 XML、JSON 类似。它的传输性能非常好，所以常被用在一些对数据传输性能要求比较高的系统中，作为数据传输格式。Protocol Buffers 的主要特性有下面这几个：

- 更快的数据传输速度：protobuf 在传输时，会将数据序列化为二进制数据，和 XML、JSON 的文本传输格式相比，这可以节省大量的 IO 操作，从而提高数据传输速度。

- 跨平台多语言：protobuf 自带的编译工具 protoc 可以基于 protobuf 定义文件，编译出不同语言的客户端或者服务端，供程序直接调用，因此可以满足多语言需求的场景。具有非常好的扩展性和兼容性，可以更新已有的数据结构，而不破坏和影响原有的程序。
  
- 基于 IDL 文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端和客户端接口。


在 gRPC 的框架中，Protocol Buffers 主要有三个作用。

1. 可以用来定义数据结构。举个例子，下面的代码定义了一个 SecretInfo 数据结构：
   ```go
    // SecretInfo contains secret details.
    message SecretInfo {
        string name = 1;
        string secret_id = 2;
        string username = 3;
        string secret_key = 4;
        int64 expires = 5;
        string description = 6;
        string created_at = 7;
        string updated_at = 8;
    }
   ```
1. 可以用来定义服务接口。下面的代码定义了一个 Cache 服务，服务包含了ListSecrets 和 ListPolicies 两个 API 接口。
   
   ```go
   // Cache implements a cache rpc service.
    service Cache{
        rpc ListSecrets(ListSecretsRequest) returns (ListSecretsResponse) {}
        rpc ListPolicies(ListPoliciesRequest) returns (ListPoliciesResponse) {}
    }
   ```

1. 可以通过 protobuf 序列化和反序列化，提升传输效率。